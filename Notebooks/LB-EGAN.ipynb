{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84c353c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets, utils as vutils\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.models.inception import inception_v3\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6791ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelId= \"<Constructed Model ID>\" #Constructed Model ID, such as LB-EGAN_Tapered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9848401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "from PIL import Image\n",
    "\n",
    "def save_class_0_images(generator, latent_dim, save_dir=f\"{ModelId}/{ModelId}_out\", n_images=500):\n",
    "    \"\"\"\n",
    "    Generate and save images for class 0 using the generator model.\n",
    "\n",
    "    Parameters:\n",
    "    - generator: The generator model.\n",
    "    - latent_dim: Dimensionality of the generator's latent input.\n",
    "    - save_dir: Directory where images will be saved.\n",
    "    - n_images: Number of images to generate and save.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    generator.eval()  # Set generator to evaluation mode\n",
    "\n",
    "    # Generate images in batches\n",
    "    batch_size = 16\n",
    "    num_batches = (n_images + batch_size - 1) // batch_size  # Number of batches needed\n",
    "    images_saved = 0\n",
    "    \n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for efficiency\n",
    "        for batch_idx in range(num_batches):\n",
    "            # Sample noise and set labels to 0 for generator input\n",
    "            z = torch.randn(batch_size, latent_dim).to(torch.device('cuda'))\n",
    "            #labels = torch.zeros(batch_size, dtype=torch.long).to(torch.device('cuda'))\n",
    "\n",
    "            # Generate images\n",
    "            gen_imgs = generator(z)\n",
    "\n",
    "            # Save images in the batch\n",
    "            for img_idx in range(min(batch_size, n_images - images_saved)):\n",
    "                img_path = os.path.join(save_dir, f\"image_{images_saved + img_idx + 1}.jpg\")\n",
    "                vutils.save_image(gen_imgs[img_idx], img_path, normalize=True)\n",
    "                #print(f\"Saved class 0 image at {img_path}\")\n",
    "            \n",
    "            images_saved += batch_size\n",
    "            if images_saved >= n_images:\n",
    "                break\n",
    "\n",
    "    print(f\"Total {n_images} images saved in '{save_dir}' directory.\")\n",
    "    generator.train()  # Restore generator to training mode\n",
    "    \n",
    "\n",
    "def load_images_in_batches(folder, transform, batch_size=64):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".BMP\"):\n",
    "            img_path = os.path.join(folder, filename)\n",
    "            try:\n",
    "                img = Image.open(img_path).convert('RGB')\n",
    "                img = transform(img)\n",
    "                images.append(img)\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading image: {filename}, Error: {e}\")\n",
    "            \n",
    "            if len(images) == batch_size:\n",
    "                yield torch.stack(images)\n",
    "                images = []  \n",
    "    if len(images) > 0:  \n",
    "        yield torch.stack(images)\n",
    "\n",
    "\n",
    "\n",
    "def save_model(epoch,save_dir=f\"{ModelId}/{ModelId}_out\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    generator_path = os.path.join(save_dir, f'generator_model.pth')\n",
    "    torch.save(generator.state_dict(), generator_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_inception_score(fake_data_loader, splits=10):\n",
    "    model = inception_v3(pretrained=True, transform_input=False).eval().to(torch.device('cuda'))\n",
    "    preds = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images in tqdm(fake_data_loader, desc=\"Calculating Inception Score\"):\n",
    "            images = images.to(torch.device('cuda'))\n",
    "            pred = F.softmax(model(images), dim=1).cpu().numpy()\n",
    "            preds.append(pred)\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)  \n",
    "    \n",
    "    scores = []\n",
    "    for i in range(splits):\n",
    "        part = preds[i * (len(preds) // splits): (i + 1) * (len(preds) // splits), :]\n",
    "        kl_div = part * (np.log(part) - np.log(np.mean(part, axis=0, keepdims=True)))\n",
    "        kl_div = np.mean(np.sum(kl_div, axis=1))\n",
    "        scores.append(np.exp(kl_div))\n",
    "    \n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "def create_fake_data_loader(generator, latent_dim, batch_size=32, num_samples=1000):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299, 299)),  \n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n",
    "    ])\n",
    "    fake_images = []\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples // batch_size):\n",
    "            z = torch.randn(batch_size, latent_dim).to(torch.device('cuda'))\n",
    "            #labels = torch.zeros(batch_size, dtype=torch.long).to(torch.device('cuda'))\n",
    "            generated_images = generator(z).to(torch.device('cuda'))\n",
    "            fake_images.append(transform(generated_images))\n",
    "    fake_images = torch.cat(fake_images)\n",
    "    return torch.utils.data.DataLoader(fake_images, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c74c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{ModelId}/{ModelId}\", exist_ok=True)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=20000, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=256, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=128, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=3, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=10, help=\"interval between image sampling\")\n",
    "opt, _ = parser.parse_known_args()\n",
    "print(opt)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Conv\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm2d\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "class Ensemble_Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Ensemble_Generator, self).__init__()\n",
    "\n",
    "        self.init_size = opt.img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        out = self.l1(noise)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "############# DRAGAN ###############\n",
    "\n",
    "class GeneratorDG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorDG, self).__init__()\n",
    "\n",
    "        self.init_size = opt.img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class DiscriminatorDG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorDG, self).__init__()\n",
    "\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(opt.channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        ds_size = opt.img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, images):\n",
    "\n",
    "        output = self.model(images)\n",
    "        output = output.view(output.shape[0], -1)\n",
    "        output = self.adv_layer(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "######## DCGAN ###########\n",
    "\n",
    "class GeneratorDC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GeneratorDC, self).__init__()\n",
    "\n",
    "        self.init_size = opt.img_size // 4\n",
    "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, noise):\n",
    "        out = self.l1(noise)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "\n",
    "class DiscriminatorDC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DiscriminatorDC, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(opt.channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        ds_size = opt.img_size // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "\n",
    "        return validity\n",
    "\n",
    "# Loss function\n",
    "crit = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "########### Ensemble GAN ###########\n",
    "\n",
    "Ensemble_Generator = Ensemble_Generator()\n",
    "\n",
    "if cuda:\n",
    "    Ensemble_Generator.cuda()\n",
    "\n",
    "\n",
    "########### DRAGAN Func. ###########\n",
    "\n",
    "# Loss weight for gradient penalty\n",
    "lambda_gp = 0.1\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generatorDG = GeneratorDG()\n",
    "discriminatorDG = DiscriminatorDG()\n",
    "\n",
    "if cuda:\n",
    "    generatorDG.cuda()\n",
    "    discriminatorDG.cuda()\n",
    "    crit.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generatorDG.apply(weights_init_normal)\n",
    "discriminatorDG.apply(weights_init_normal)\n",
    "\n",
    "\n",
    "########## DCGAN Func. ############\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "generatorDC = GeneratorDC()\n",
    "discriminatorDC = DiscriminatorDC()\n",
    "\n",
    "if cuda:\n",
    "    generatorDC.cuda()\n",
    "    discriminatorDC.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "generatorDC.apply(weights_init_normal)\n",
    "discriminatorDC.apply(weights_init_normal)\n",
    "\n",
    "\n",
    "############ DATASET ###############\n",
    "\n",
    "# Configure data loader\n",
    "data_path =  \"\" # Should be the path of the original dataset\n",
    "\n",
    "dataset = ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize((opt.img_size, opt.img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5], [0.5])\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=opt.batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "############### DRAGAN OPT. #################\n",
    "\n",
    "# Optimizers\n",
    "optimizer_DG = torch.optim.Adam(generatorDG.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_DD = torch.optim.Adam(discriminatorDG.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "\n",
    "############### DCGAN OPT. #################\n",
    "\n",
    "# Optimizers\n",
    "optimizer_DC = torch.optim.Adam(generatorDC.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_DC = torch.optim.Adam(discriminatorDC.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "\n",
    "############## Other Func. #################\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "def compute_gradient_penalty(D, X):\n",
    "    \"\"\"Calculates the gradient penalty loss for DRAGAN\"\"\"\n",
    "    \n",
    "    alpha = FloatTensor(np.random.random(size=X.shape)).to(X.device)\n",
    "\n",
    "    interpolates = alpha * X + ((1 - alpha) * (X + 0.5 * X.std() * torch.rand(X.size(), device=X.device)))\n",
    "    interpolates = Variable(interpolates, requires_grad=True)\n",
    "\n",
    "    d_interpolates = D(interpolates)\n",
    "\n",
    "    fake = Variable(FloatTensor(X.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "\n",
    "    gradients = autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True,\n",
    "    )[0]\n",
    "\n",
    "    gradient_penalty = lambda_gp * ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row ** 2, opt.latent_dim))))\n",
    "    \n",
    "    gen_imgs = Ensemble_Generator(z)\n",
    "    save_image(gen_imgs.data, f\"{ModelId}/{ModelId}/%d.png\" % batches_done, nrow=n_row, normalize=True)\n",
    "\n",
    "\n",
    "\n",
    "def FIDCalc(): #Calculate the FID score between the original and generated images. \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((299,299)),  # Inception v3 \n",
    "        transforms.ToTensor(),  \n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Inception model \n",
    "        ])\n",
    "    \n",
    "    original_dataset_paths = [\"<Original Dataset Path>\"] #Should be the path of the original dataset.\n",
    "\n",
    "    synthetic_dataset_path = f'.../{ModelId}/{ModelId}_out' #Should be the path of the generated images.\n",
    "    synthetic_images = load_images_in_batches(synthetic_dataset_path, transform)\n",
    "\n",
    "    fid = FrechetInceptionDistance(normalize=True).to(torch.device('cuda'))\n",
    "\n",
    "    for original_dataset_path in original_dataset_paths:\n",
    "        for batch in load_images_in_batches(original_dataset_path, transform):\n",
    "            batch.size()\n",
    "            fid.update(batch.to(torch.device('cuda')), real=True)\n",
    "\n",
    "    for batch in load_images_in_batches(synthetic_dataset_path, transform):\n",
    "        fid.update(batch.to(torch.device('cuda')), real=False)\n",
    "\n",
    "\n",
    "    fid_score = fid.compute()\n",
    "    \n",
    "    return fid_score\n",
    "\n",
    "def save_model(epoch,save_dir=f\"{ModelId}/{ModelId}_Out\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    generator_path = os.path.join(save_dir, f'generator_model.pth')\n",
    "    torch.save(Ensemble_Generator.state_dict(), generator_path)\n",
    "\n",
    "\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "fid_p=9999\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        \n",
    "        \n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, opt.latent_dim))))\n",
    "\n",
    "\n",
    "        ############ DRAGAN TR ###############\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_DG.zero_grad()\n",
    "\n",
    "        #gen_labels = Variable(LongTensor(np.random.randint(0, opt.n_classes, batch_size)))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgsDG = generatorDG(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity = discriminatorDG(gen_imgsDG)\n",
    "        dg_loss = crit(validity, valid)\n",
    "\n",
    "        dg_loss.backward()\n",
    "        optimizer_DG.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_DD.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        validity_real = discriminatorDG(real_imgs)\n",
    "        d_real_loss = crit(validity_real, valid)\n",
    "\n",
    "        # Loss for fake images\n",
    "        validity_fake = discriminatorDG(gen_imgsDG.detach())\n",
    "        d_fake_loss = crit(validity_fake, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        dd_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        # Calculate gradient penalty\n",
    "        gradient_penalty = compute_gradient_penalty(discriminatorDG, real_imgs.data)\n",
    "        dd_loss = gradient_penalty + dd_loss\n",
    "        dd_loss.backward()\n",
    "\n",
    "        optimizer_DD.step()\n",
    "\n",
    "        ############## DCGAN TR. #################\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_DC.zero_grad()\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgsDC = generatorDC(z)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        DCg_loss = crit(discriminatorDC(gen_imgsDC), valid)\n",
    "\n",
    "        DCg_loss.backward()\n",
    "        optimizer_DC.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_DC.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        DCreal_loss = crit(discriminatorDC(real_imgs), valid)\n",
    "        DCfake_loss = crit(discriminatorDC(gen_imgsDC.detach()), fake)\n",
    "        DCd_loss = (DCreal_loss + DCfake_loss) / 2\n",
    "\n",
    "        DCd_loss.backward()\n",
    "        optimizer_DC.step()\n",
    "\n",
    "\n",
    "        ############## Ensemble GAN ##############\n",
    "\n",
    "        w1 = 1 / DCd_loss\n",
    "        w2 = 1 / dd_loss\n",
    "        total_weight = w1 + w2\n",
    "        w1 /= total_weight\n",
    "        w2 /= total_weight\n",
    "\n",
    "\n",
    "        weighted_state_dict = {}\n",
    "        for key in Ensemble_Generator.state_dict().keys():\n",
    "            weighted_state_dict[key] = w1 * generatorDC.state_dict()[key] + w2 * generatorDG.state_dict()[key]\n",
    "\n",
    "\n",
    "\n",
    "        Ensemble_Generator.load_state_dict(weighted_state_dict)\n",
    "\n",
    "        generatorDC.load_state_dict(Ensemble_Generator.state_dict())\n",
    "        generatorDG.load_state_dict(Ensemble_Generator.state_dict())\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [DCD loss: %f] [DD loss: %f] [DCG loss: %f] [DG loss: %f]\"\n",
    "            % (epoch, opt.n_epochs, i, len(dataloader), DCd_loss.item(), dd_loss.item(), DCg_loss.item(), dg_loss.item())\n",
    "        )\n",
    "        \n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        epoch_done = epoch\n",
    "        if epoch_done % opt.sample_interval == 0 and i == 2:\n",
    "            sample_image(n_row=4, batches_done=epoch_done)\n",
    "            save_class_0_images(generator = Ensemble_Generator, latent_dim = opt.latent_dim)\n",
    "            fid_c = FIDCalc()  \n",
    "            f = open(f\"{ModelId}/FID_Scores_{ModelId}.txt\", \"a\")\n",
    "            f.write(\"\\n\" + str(fid_c))\n",
    "            if fid_p > fid_c:\n",
    "                save_model(epoch)  \n",
    "                fid_p = fid_c  \n",
    "                print(fid_p)\n",
    "            fake_loader = create_fake_data_loader(Ensemble_Generator, latent_dim=100)\n",
    "            is_mean, is_std = calculate_inception_score(fake_loader)\n",
    "            print(f\"Inception Score: {is_mean:.2f} ± {is_std:.2f}\")\n",
    "            I = open(f\"{ModelId}/IS_{ModelId}.txt\", \"a\")\n",
    "            I.write(\"\\n\" + str(is_mean))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
